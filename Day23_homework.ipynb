{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day23_homework.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gCIvz30AOj-H"},"source":["# 作業 : 觀察機器翻譯 ATTENTION 內容 \n","- 仔細地觀察機器翻譯 ATTENTION 結果"]},{"cell_type":"markdown","metadata":{"id":"usP1_X7qOv6F"},"source":["# [作業目標]\n","- 透過視覺化 注意力 attention 層 了解attention 的作用方式"]},{"cell_type":"markdown","metadata":{"id":"fWGLeN9BOxEF"},"source":["# [作業重點]\n","- 透過視覺化 注意力 attention 層 了解attention 的作用方式\n","- 原則上只要之前的訓練有跑完，這邊的程式可以執行成功最後只要觀察結果就好\n"]},{"cell_type":"code","metadata":{"id":"UIBD2Nn-OI-1","executionInfo":{"status":"ok","timestamp":1620287257270,"user_tz":-480,"elapsed":1597,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}}},"source":["import re\n","import math\n","import time\n","import random\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from torchtext.data.utils import get_tokenizer"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"BrbNQhl5R2MP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620287257270,"user_tz":-480,"elapsed":1584,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}},"outputId":"3be33033-67bf-480d-ca56-2817cbb5927b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wFjVGqegR5U8","executionInfo":{"status":"ok","timestamp":1620287257271,"user_tz":-480,"elapsed":1570,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}},"outputId":"6872c804-42e9-4149-f4ff-f67391535cfc"},"source":["data_dir = '/content/drive/My Drive/DL_NLP_marathon/data/'\n","lines = open(data_dir + 'cmn.txt' , encoding='utf-8').read().strip().split('\\n')\n","trnslt_pairs = [[s for s in l.split('\\t')] for l in lines ]\n","print (\"Sample:\", trnslt_pairs[1000][0:2])\n","print (\"Total records:\", len(trnslt_pairs))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Sample: ['He was drowned.', '他被淹死了。']\n","Total records: 24360\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nspf5OQ_MNni","executionInfo":{"status":"ok","timestamp":1620287259370,"user_tz":-480,"elapsed":3654,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}},"outputId":"cb360d62-4eea-4e1c-e198-0bf9a9048a58"},"source":["# 下載 spacy 的英文模型 幫我們做tokenize\n","en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n","\n","# 讀取之前儲存的 vocabulary\n","model_dir =  '/content/drive/My Drive/DL_NLP_marathon/model/'\n","cmn_vocab = torch.load(model_dir + 'cmn_vocab.pt')\n","en_vocab = torch.load(model_dir + 'en_vocab.pt')\n","print (\"中文語料的字元表長度: \" , len(cmn_vocab) , \", 英文的字元表長度: \" ,len(en_vocab))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["中文語料的字元表長度:  2701 , 英文的字元表長度:  4235\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EQYeBoJ8M37B","executionInfo":{"status":"ok","timestamp":1620287654538,"user_tz":-480,"elapsed":398806,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}}},"source":["def data_process(filepath):\n","    raw_data = pd.read_csv(filepath, names=['en', 'cmn'])\n","    data = []\n","    for (raw_cmn, raw_en) in zip(raw_data['cmn'], raw_data['en']):\n","        cmn_tensor_ = torch.tensor([cmn_vocab[token] for token in raw_cmn], dtype=torch.long)\n","        en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)], dtype=torch.long)\n","        data.append((cmn_tensor_, en_tensor_))\n","    return data\n","\n","train_filepath = data_dir + 'train.csv'\n","val_filepath = data_dir + 'val.csv'\n","test_filepath = data_dir + 'test.csv'\n","\n","train_data = data_process(train_filepath)\n","val_data = data_process(val_filepath)\n","test_data = data_process(test_filepath)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwSJf2TMM4qP","executionInfo":{"status":"ok","timestamp":1620287654540,"user_tz":-480,"elapsed":398802,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","BATCH_SIZE = 512\n","PAD_IDX = en_vocab['<pad>']\n","BOS_IDX = en_vocab['<bos>']\n","EOS_IDX = en_vocab['<eos>']\n","\n","def generate_batch(data_batch):\n","    en_batch, cmn_batch = [], []\n","    cmn_lens = []\n","    for (cmn_item, en_item) in data_batch:\n","        cmn_seq = torch.cat([torch.tensor([BOS_IDX]), cmn_item, torch.tensor([EOS_IDX])], dim=0)\n","        cmn_batch.append(cmn_seq)\n","        cmn_lens.append(len(cmn_seq))\n","        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n","\n","    sorted_idx = sorted(range(len(cmn_lens)), key=lambda k: cmn_lens[k], reverse=True)\n","    cmn_batch = [cmn_batch[i] for i in sorted_idx]\n","    cmn_lens = torch.tensor([cmn_lens[i] for i in sorted_idx])\n","    en_batch = [en_batch[i] for i in sorted_idx]\n","    \n","    cmn_batch = pad_sequence(cmn_batch, padding_value=PAD_IDX)\n","    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n","\n","    return (cmn_batch, cmn_lens), en_batch\n","\n","\n","train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n","                        shuffle=True, collate_fn=generate_batch)\n","valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n","                        shuffle=True, collate_fn=generate_batch)\n","test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n","                       shuffle=True, collate_fn=generate_batch)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lYoqlKcrq2Z_"},"source":["# 模型主體 和前面範例程式一樣\n","\n"]},{"cell_type":"code","metadata":{"id":"wj3ZTHDMSGOF","executionInfo":{"status":"ok","timestamp":1620287654540,"user_tz":-480,"elapsed":398795,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}}},"source":["class Attention(nn.Module):\n","    def __init__(self, enc_hid_dim, dec_hid_dim):\n","        super().__init__()\n","\n","    def forward(self, dec_input, encoder_outputs, mask):\n","        # dec_input shape: [1, bz, dec_emb_dim]\n","        # encoder_outputs shape: [src len, bz, enc_hid_dim x 2]\n","        # mask  hape: [bz, src len]\n","\n","        batch_size = encoder_outputs.shape[1]\n","        src_len = encoder_outputs.shape[0]\n","\n","        dec_input = dec_input.permute(1,0,2) \n","        # dec_input shape: [bz ,1 , dec_emb_dim]\n","\n","        attention = torch.matmul(dec_input , encoder_outputs.permute(1, 2, 0))\n","        # [bz ,1 , dec_emb_dim] @ [bz, enc_hid_dim x 2, src len]\n","        # attention shape: [bz, 1, src len]\n","\n","        attention = attention.squeeze(1)\n","        # squeeze bz , src len\n","\n","        attention = attention.masked_fill(mask == 0, -1e10)\n","\n","        return F.softmax(attention, dim = 1)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNzgZqHcS2CX","executionInfo":{"status":"ok","timestamp":1620287654541,"user_tz":-480,"elapsed":398790,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}}},"source":["class RNNEncoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n","        super().__init__()\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)  # 雙向 GRU encoder \n","        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src, src_len):\n","        # src shape: [src len, bz]\n","        # src_len shape: [ bz ]\n","\n","        embedded = self.dropout(self.embedding(src))\n","        # embedded shape [src len, bz, emb dim]\n","                \n","        # 使用pack_padded_sequence 來壓縮序列並使用 pad_packed_sequence 用來展開序列成原本形狀\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n","        packed_outputs, hidden = self.rnn(packed_embedded)\n","        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n","        # outputs shape: [src len, bz, (hid dim * num directions)]\n","        # hidden shape: [(n layers * num directions), bz, hid dim]\n","        # hidden 堆疊 [forward_1, backward_1, forward_2, backward_2, ...]\n","        # outputs 是最後一層 \n","        \n","        # hidden [-2, :, : ] 是最後一層 forwards RNN \n","        # hidden [-1, :, : ] 是最後一層 backwards RNN\n","        \n","        # hidden 是最後再過一層 dense layer\n","        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n","        \n","        # outputs shape [src len, bz, hid dim * 2]\n","        # hidden shape [bz, hid dim]\n","        \n","        return outputs, hidden\n","\n","class RNNDecoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n","        super().__init__()\n","        self.output_dim = output_dim\n","        self.attention = attention\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        # 單向 GRU decoder \n","        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n","        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, encoder_outputs, mask):   \n","        # input shape: [ bz ]\n","        # hidden shape: [bz, dec hid dim]\n","        # encoder_outputs shape: [src len, bz, enc hid dim * 2]\n","        # mask shape: [bz, src len]\n","        \n","        input = input.unsqueeze(0)\n","        #input shape: [1, bz]\n","        embedded = self.dropout(self.embedding(input))\n","        #embedded shape: [1, bz, emb dim]\n","        \n","        a = self.attention(embedded, encoder_outputs, mask)\n","        # a shape: [bz, src len]\n","        a = a.unsqueeze(1)\n","        # a shape: [bz, 1, src len]\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        # encoder_outputs shape: [bz, src len, enc hid dim * 2]\n","        weighted = torch.bmm(a, encoder_outputs)\n","        # weighted shape: [bz, 1, enc hid dim * 2]\n","        weighted = weighted.permute(1, 0, 2)\n","        # weighted shape: [1, bz, enc hid dim * 2]\n","        \n","        rnn_input = torch.cat((embedded, weighted), dim = 2)\n","        # rnn_input shape: [1, bz, (enc hid dim * 2) + emb dim]\n","            \n","        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n","        # output shape: [seq len, bz, (dec hid dim * n directions)]\n","        # hidden shape: [(n layers * n directions), bz, dec hid dim]\n","        \n","        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n","        # output shape [1, bz, dec hid dim]\n","        # hidden shape [1, bz, dec hid dim]\n","        # this also means that output == hidden\n","        assert (output == hidden).all()\n","        \n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","        \n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n","        # prediction shape: [bz, output dim]\n","        \n","        return prediction, hidden.squeeze(0), a.squeeze(1)\n","\n","class Seq2SeqATTN(nn.Module):\n","    def __init__(self, encoder, decoder, src_pad_idx, device):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_pad_idx = src_pad_idx\n","        self.device = device\n","        \n","    def create_mask(self, src):\n","        mask = (src != self.src_pad_idx).permute(1, 0)\n","        return mask\n","        \n","    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n","        # src shape: [src len, bz]\n","        # src_len shape: [bz]\n","        # trg shape: [trg len, bz]\n","        # teacher_forcing_ratio is probability to use teacher forcing\n","        # e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n","                    \n","        batch_size = src.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        # tensor to store decoder outputs\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        \n","        # encoder_outputs is all hidden states of the input sequence, back and forwards\n","        # hidden is the final forward and backward hidden states, passed through a linear layer\n","        encoder_outputs, hidden = self.encoder(src, src_len)\n","                \n","        # first input to the decoder is the <sos> tokens\n","        input = trg[0,:]\n","        \n","        mask = self.create_mask(src)\n","        # mask = [bz, src len]\n","                \n","        for t in range(1, trg_len):           \n","            # insert input token embedding, previous hidden state, all encoder hidden states \n","            #  and mask\n","            # receive output tensor (predictions) and new hidden state\n","            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n","            # place predictions in a tensor holding predictions for each token\n","            outputs[t] = output\n","            \n","            # decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            # get the highest predicted token from our predictions\n","            top1 = output.argmax(1) \n","            \n","            # if teacher forcing, use actual next token as next input\n","            # if not, use predicted token\n","            input = trg[t] if teacher_force else top1\n","            \n","        return outputs"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pW2KIxhxrMGf"},"source":["# 建立模型和重要參數 請保持和前面訓練時一樣"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybIY0kKGS_gI","executionInfo":{"status":"ok","timestamp":1620287656473,"user_tz":-480,"elapsed":400716,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}},"outputId":"fd1aea66-4558-4aea-c6f0-6d197e1ded5d"},"source":["INPUT_DIM = len(cmn_vocab)\n","OUTPUT_DIM = len(en_vocab)\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 512\n","ENC_HID_DIM = 256 # 注意 encoder hidden layer 設定 必須為 dec 的一半 \n","DEC_HID_DIM = 512\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","SRC_PAD_IDX = cmn_vocab['<pad>']\n","TRG_PAD_IDX = en_vocab['<pad>']\n","\n","LEARNING_RATE = 0.002\n","\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = RNNEncoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n","dec = RNNDecoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n","model = Seq2SeqATTN(enc, dec, SRC_PAD_IDX, device).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n","\n","\n","def initial_mdl_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","            \n","model.apply(initial_mdl_weights)\n","print (\"模型全部參數量: {:10,d} \".format(sum(p.numel() for p in model.parameters())))\n","model"],"execution_count":9,"outputs":[{"output_type":"stream","text":["模型全部參數量: 12,783,499 \n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Seq2SeqATTN(\n","  (encoder): RNNEncoder(\n","    (embedding): Embedding(2701, 256)\n","    (rnn): GRU(256, 256, bidirectional=True)\n","    (fc): Linear(in_features=512, out_features=512, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): RNNDecoder(\n","    (attention): Attention()\n","    (embedding): Embedding(4235, 512)\n","    (rnn): GRU(1024, 512)\n","    (fc_out): Linear(in_features=1536, out_features=4235, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"KOpjxQJmTDYU","executionInfo":{"status":"ok","timestamp":1620287656474,"user_tz":-480,"elapsed":400703,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}}},"source":["def evaluate(model, iterator, criterion):\n","    model.eval()\n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","        for i, batch in enumerate(iterator):\n","            src, src_len = batch[0]\n","            trg = batch[1]\n","            src = src.to(device)\n","            trg = trg.to(device)\n","\n","            output = model(src, src_len.cpu(), trg, 0) # turn off teacher forcing\n","            \n","            # trg shape: [trg len, batch size]\n","            # output shape: [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","            # trg shape: [(trg len - 1) * batch size]\n","            # output shape: [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ukg9t_iOTHlG","executionInfo":{"status":"ok","timestamp":1620287657030,"user_tz":-480,"elapsed":401252,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}},"outputId":"e934ce90-a190-4c94-cdcb-4cfc2a2938e8"},"source":["model_dir =  '/content/drive/My Drive/DL_NLP_marathon/model/'\n","model.load_state_dict(torch.load(model_dir + 'best-model.pt'))\n","test_loss = evaluate(model, test_iter, criterion)\n","\n","print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["| Test Loss: 3.563 | Test PPL:  35.276 |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q-caE1Y1TL5p","executionInfo":{"status":"ok","timestamp":1620287657031,"user_tz":-480,"elapsed":401239,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}}},"source":["def translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len = 50):       \n","    # if isinstance(sentence, str):\n","    #     en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n","    #     tokens = [token.text.lower() for token in en_tokenizer(sentence)]\n","    # else:\n","    #     tokens = [token.lower() for token in sentence]\n","\n","    model.eval()\n","\n","    tokens = [token.lower() for token in sentence]    \n","    tokens = ['<bos>'] + tokens + ['<eos>']\n","        \n","    src_indexes = [src_vocab.stoi[token] for token in tokens]\n","    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n","    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n","    \n","    with torch.no_grad():\n","        encoder_outputs, hidden = model.encoder(src_tensor, src_len.cpu())\n","\n","    mask = model.create_mask(src_tensor)\n","    trg_indexes = [trg_vocab['<bos>']]\n","    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n","    \n","    for i in range(max_len):\n","        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n","                \n","        with torch.no_grad():\n","            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n","\n","        attentions[i] = attention\n","        pred_token = output.argmax(1).item()\n","        trg_indexes.append(pred_token)\n","\n","        if pred_token == trg_vocab['<eos>']:\n","            break\n","    \n","    trg_tokens = [trg_vocab.itos[i] for i in trg_indexes]\n","    \n","    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V4n7915Mrcs1"},"source":["# 作業重點\n","## 請選擇一個好的翻譯結果\n","## 將其 ATTENTION 視覺化 \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRYXjqgvYb-E","executionInfo":{"status":"ok","timestamp":1620287657031,"user_tz":-480,"elapsed":401232,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}},"outputId":"e8f26d13-96aa-40e4-ebb4-be8667924c60"},"source":["# 請在這邊自行調整 sample index \n","# 觀察不同句子的 ATTENTION 結果\n","example_idx = 699\n","\n","src = [cmn_vocab.itos[idx] for idx in train_data[example_idx][0]]\n","trg = [en_vocab.itos[idx] for idx in train_data[example_idx][1]]\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')\n","\n","translation, attention = translate_sentence(src, cmn_vocab, en_vocab, model, device)\n","\n","print(f'predicted trg = {translation}')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["src = ['我', '们', '应', '该', '做', '到', '最', '好', '。']\n","trg = ['We', 'have', 'to', 'do', 'our', 'best', '.']\n","predicted trg = ['We', 'should', 'have', 'to', 'do', 'that', '.', '<eos>']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQoAR8K-RyHd","executionInfo":{"status":"ok","timestamp":1620287660439,"user_tz":-480,"elapsed":404625,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}},"outputId":"ccc1c5eb-0816-497e-fc1e-e79afb219aa3"},"source":["# Colab 進行matplotlib繪圖時顯示繁體中文\n","# 下載字體並命名taipei_sans_tc_beta.ttf，移至指定路徑\n","!wget -O taipei_sans_tc_beta.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\n","!mv taipei_sans_tc_beta.ttf /usr/local/lib/python3.7/dist-packages/matplotlib//mpl-data/fonts/ttf\n","\n","from matplotlib.font_manager import FontProperties\n","import matplotlib.pyplot as plt \n","plt.style.use(\"seaborn-whitegrid\")\n","import matplotlib.ticker as ticker\n","# 自定義字體變數\n","myfont = FontProperties(fname=r'/usr/local/lib/python3.7/dist-packages/matplotlib/mpl-data/fonts/ttf/taipei_sans_tc_beta.ttf')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["--2021-05-06 07:54:16--  https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_\n","Resolving drive.google.com (drive.google.com)... 108.177.125.100, 108.177.125.102, 108.177.125.139, ...\n","Connecting to drive.google.com (drive.google.com)|108.177.125.100|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hk8ikhg45f5ndnaof9r40550d4unqp3l/1620287625000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-05-06 07:54:18--  https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hk8ikhg45f5ndnaof9r40550d4unqp3l/1620287625000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_\n","Resolving doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)... 108.177.125.132, 2404:6800:4008:c01::84\n","Connecting to doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)|108.177.125.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/x-font-ttf]\n","Saving to: ‘taipei_sans_tc_beta.ttf’\n","\n","taipei_sans_tc_beta     [ <=>                ]  19.70M   126MB/s    in 0.2s    \n","\n","2021-05-06 07:54:19 (126 MB/s) - ‘taipei_sans_tc_beta.ttf’ saved [20659344]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9jhh_5_SYYLT","executionInfo":{"status":"ok","timestamp":1620287660440,"user_tz":-480,"elapsed":404610,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}}},"source":["def display_attention(sentence, translation, attention):\n","    fig = plt.figure(figsize=(10,10))\n","    ax = fig.add_subplot(111)\n","    \n","    attention = attention.squeeze(1).cpu().detach().numpy()\n","    cax = ax.matshow(attention, cmap='bone')\n","    \n","    ax.tick_params(labelsize=15)\n","    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n","                       fontproperties=myfont)\n","    ax.set_yticklabels(['']+translation, fontproperties=myfont)\n","\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","    plt.close()"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2cdlptGJrsfv"},"source":["# 請觀察翻譯文 和被翻譯文的語意對應"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"_798-TSFgtZG","executionInfo":{"status":"ok","timestamp":1620287661086,"user_tz":-480,"elapsed":405249,"user":{"displayName":"chi-fen Liao","photoUrl":"","userId":"16137842954465597187"}},"outputId":"ee0227fe-dc46-49f4-cacb-00e172751f81"},"source":["print(\"\".join(src))\n","display_attention(src, translation, attention)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["我们应该做到最好。\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x720 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}