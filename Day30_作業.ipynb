{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WypXKFXKjTIi"
   },
   "source": [
    "# 作業 : 微調輕量化 Bert 預訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "od09om0ijTIl"
   },
   "source": [
    "# [作業目標]\n",
    "- 觀察切換 distilBERT 及 Bert 模型帶來的影響\n",
    "- 嘗試並了解前處理對輕量化 Bert 模型帶來的影響"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upbSRmCRjTIl"
   },
   "source": [
    "# [作業重點]\n",
    "- 試著替換不同的預訓練模型 (DistilBERT / Bert)，觀察有何不同\n",
    "(Hint : 在 In[7] 可以用註解切換不同模型) \n",
    "- 試著註解或跳過\"前處理\"的3個步驟，觀察有何不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1621865977028,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "tgQRbEw8jxBy",
    "outputId": "ec0a1248-7348-4083-a516-09347f3989e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 24 14:19:36 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   49C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4377,
     "status": "ok",
     "timestamp": 1621865983561,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "GhcaDhjUj56A",
    "outputId": "44f05078-8d13-4b91-e6ac-ba5c510be6c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1621865983562,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "TUpvrNmclY8g",
    "outputId": "1c708ff9-3411-4682-e900-5080e21c8247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1597,
     "status": "ok",
     "timestamp": 1621865987865,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "LLUMPEy4jTIm"
   },
   "outputs": [],
   "source": [
    "# 載入相關套件, 第一次執行前需安裝 transformers 套件\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1621865990278,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "ZmEbQMqgjTIm"
   },
   "outputs": [],
   "source": [
    "# 載入訓練與測試資料\n",
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFSSmiJijTIn"
   },
   "source": [
    "# 前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 867,
     "status": "ok",
     "timestamp": 1621865994131,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "SEtzFqhfjTIn"
   },
   "outputs": [],
   "source": [
    "# 前處理-1 : 消除連字\n",
    "def decontracted(text):\n",
    "    # 特殊連字\n",
    "    text = re.sub(r\"(W|w)on(\\'|\\’)t \", \"will not \", text)\n",
    "    text = re.sub(r\"(C|c)an(\\'|\\’)t \", \"can not \", text)\n",
    "    text = re.sub(r\"(Y|y)(\\'|\\’)all \", \"you all \", text)\n",
    "    text = re.sub(r\"(Y|y)a(\\'|\\’)ll \", \"you all \", text)\n",
    "    # 一般性連字\n",
    "    text = re.sub(r\"(I|i)(\\'|\\’)m \", \"i am \", text)\n",
    "    text = re.sub(r\"(A|a)in(\\'|\\’)t \", \"is not \", text)\n",
    "    text = re.sub(r\"n(\\'|\\’)t \", \" not \", text)\n",
    "    text = re.sub(r\"(\\'|\\’)re \", \" are \", text)\n",
    "    text = re.sub(r\"(\\'|\\’)s \", \" is \", text)\n",
    "    text = re.sub(r\"(\\'|\\’)d \", \" would \", text)\n",
    "    text = re.sub(r\"(\\'|\\’)ll \", \" will \", text)\n",
    "    text = re.sub(r\"(\\'|\\’)t \", \" not \", text)\n",
    "    text = re.sub(r\"(\\'|\\’)ve \", \" have \", text)\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: decontracted(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x: decontracted(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1621865996761,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "QSsI3PTRjTIp"
   },
   "outputs": [],
   "source": [
    "# 前處理-2 : 清除特殊符號\n",
    "import string\n",
    "regular_punct = list(string.punctuation)\n",
    "extra_punct = [\n",
    "    ',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&',\n",
    "    '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    "    '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n",
    "    '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n",
    "    '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n",
    "    '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n",
    "    '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "    'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
    "    '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
    "    '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']\n",
    "# 消除標點符號以及上列符號\n",
    "all_punct = list(set(regular_punct + extra_punct))\n",
    "# 消除連字號 \"-\" 以及句號 \".\"\n",
    "all_punct.remove('-')\n",
    "all_punct.remove('.')\n",
    "\n",
    "def spacing_punctuation(text):\n",
    "    \"\"\"\n",
    "    add space before and after punctuation and symbols\n",
    "    \"\"\"\n",
    "    for punc in all_punct:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, f' {punc} ')\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: spacing_punctuation(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x: spacing_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 650,
     "status": "ok",
     "timestamp": 1621866001053,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "LDvzlxGZjTIp"
   },
   "outputs": [],
   "source": [
    "# 前處理-3 : 錯漏字修正\n",
    "mis_connect_list = ['(W|w)hat', '(W|w)hy', '(H|h)ow', '(W|w)hich', '(W|w)here', '(W|w)ill']\n",
    "mis_connect_re = re.compile('(%s)' % '|'.join(mis_connect_list))\n",
    "\n",
    "mis_spell_mapping = {'whattsup': 'WhatsApp', 'whatasapp':'WhatsApp', 'whatsupp':'WhatsApp', \n",
    "                      'whatcus':'what cause', 'arewhatsapp': 'are WhatsApp', 'Hwhat':'what',\n",
    "                      'Whwhat': 'What', 'whatshapp':'WhatsApp', 'howhat':'how that',\n",
    "                      # why\n",
    "                      'Whybis':'Why is', 'laowhy86':'Foreigners who do not respect China',\n",
    "                      'Whyco-education':'Why co-education',\n",
    "                      # How\n",
    "                      \"Howddo\":\"How do\", 'Howeber':'However', 'Showh':'Show',\n",
    "                      \"Willowmagic\":'Willow magic', 'WillsEye':'Will Eye', 'Williby':'will by'}\n",
    "def spacing_some_connect_words(text):\n",
    "    \"\"\"\n",
    "    'Whyare' -> 'Why are'\n",
    "    \"\"\"\n",
    "    ori = text\n",
    "    for error in mis_spell_mapping:\n",
    "        if error in text:\n",
    "            text = text.replace(error, mis_spell_mapping[error])\n",
    "            \n",
    "    # what\n",
    "    text = re.sub(r\" (W|w)hat+(s)*[A|a]*(p)+ \", \" WhatsApp \", text)\n",
    "    text = re.sub(r\" (W|w)hat\\S \", \" What \", text)\n",
    "    text = re.sub(r\" \\S(W|w)hat \", \" What \", text)\n",
    "    # why\n",
    "    text = re.sub(r\" (W|w)hy\\S \", \" Why \", text)\n",
    "    text = re.sub(r\" \\S(W|w)hy \", \" Why \", text)\n",
    "    # How\n",
    "    text = re.sub(r\" (H|h)ow\\S \", \" How \", text)\n",
    "    text = re.sub(r\" \\S(H|h)ow \", \" How \", text)\n",
    "    # which\n",
    "    text = re.sub(r\" (W|w)hich\\S \", \" Which \", text)\n",
    "    text = re.sub(r\" \\S(W|w)hich \", \" Which \", text)\n",
    "    # where\n",
    "    text = re.sub(r\" (W|w)here\\S \", \" Where \", text)\n",
    "    text = re.sub(r\" \\S(W|w)here \", \" Where \", text)\n",
    "    \n",
    "    text = mis_connect_re.sub(r\" \\1 \", text)\n",
    "    text = text.replace(\"What sApp\", 'WhatsApp') \n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: spacing_some_connect_words(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x: spacing_some_connect_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 1086,
     "status": "ok",
     "timestamp": 1621866005420,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "q-T2_OWhjTIq",
    "outputId": "2e15ca24-7d53-497a-d237-a30a4cb01d73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this  # earthquake...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to  ' shelter in place '  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13 , 000 people receive  # wildfires evacuatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby  # Alaska a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword  ...                                               text target\n",
       "0   1     NaN  ...  Our Deeds are the Reason of this  # earthquake...      1\n",
       "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
       "2   5     NaN  ...  All residents asked to  ' shelter in place '  ...      1\n",
       "3   6     NaN  ...  13 , 000 people receive  # wildfires evacuatio...      1\n",
       "4   7     NaN  ...  Just got sent this photo from Ruby  # Alaska a...      1\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYI5RVfrjTIs"
   },
   "source": [
    "# 載入 distilBERT 模型或 Bert 模型, 將文字編碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7385,
     "status": "ok",
     "timestamp": 1621866016342,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "8JPtefYqjTIs",
    "outputId": "7a265ebe-2dd2-4159-d619-ec2ef7b5e8f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# 載入 distilBERT 模型或 Bert 模型 (下列兩行中, 將不選的模型註解掉即可)\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# 載入預訓練權重以及 tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe1eqmhtjTIt"
   },
   "source": [
    "# 將訓練資料經由 distilBERT 或 Bert 轉換為 Embedding 編碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6139,
     "status": "ok",
     "timestamp": 1621866025585,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "Ueh6byVYjTIt"
   },
   "outputs": [],
   "source": [
    "# 將訓練資料經過 tokenizer 編碼轉換\n",
    "tokenized = df['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1621866028388,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "Bde7jtd2jTIu"
   },
   "outputs": [],
   "source": [
    "# 以最長字串為準, 將訓練資料補零成相同長度\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 34076,
     "status": "ok",
     "timestamp": 1621866331653,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "ntIsIg4PjTIu"
   },
   "outputs": [],
   "source": [
    "# 設定 attention_mask, 將計算經過 Bert 生成的 Embedding 結果, 儲存於 last_hidden_states 中\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask = torch.tensor(attention_mask).to(torch.int32).to(device)\n",
    "input_ids = torch.tensor(padded).to(torch.int32).to(device)\n",
    "\n",
    "model = model.to(device)\n",
    "batch_size = 512\n",
    "turns = input_ids.size(0) // batch_size + 1\n",
    "\n",
    "last_hidden_states = np.zeros((input_ids.size(0), model.config.dim))\n",
    "with torch.no_grad():\n",
    "    for i in range(turns):\n",
    "        begin_idx = i * batch_size\n",
    "        end_idx = begin_idx + batch_size\n",
    "        data = input_ids[begin_idx : end_idx]\n",
    "        mask = attention_mask[begin_idx : end_idx]\n",
    "        last_hidden_state = model(data, attention_mask=mask)\n",
    "        \n",
    "        last_hidden_states[begin_idx : end_idx] = last_hidden_state[0][:, 0, :].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1621866501152,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "el19fsjljTIv"
   },
   "outputs": [],
   "source": [
    "# 準備下一階段要用的特徵 (上階段 Embedding 結果) 與目標值\n",
    "labels = df['target']\n",
    "# 切割訓練 / 測試集\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(last_hidden_states, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0iYIT-9jTIw"
   },
   "source": [
    "# 使用 Logistic Regression 當作最後一層, 輸出預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39526,
     "status": "ok",
     "timestamp": 1621866552065,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "jWlMkGYpjTIw",
    "outputId": "de81a823-a17d-422a-8857-52674ffd3eeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 5.263252631578947}\n",
      "best scrores:  0.8064434829189377\n"
     ]
    }
   ],
   "source": [
    "# 對 Logistic Regression 跑參, 相當於加上單層類神經網路\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
    "grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
    "grid_search.fit(train_features, train_labels)\n",
    "print('best parameters: ', grid_search.best_params_)\n",
    "print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1230,
     "status": "ok",
     "timestamp": 1621866571493,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "WkVvYuuTjTIx",
    "outputId": "ec5a84d7-f91e-4ddb-a312-88a5ec009042"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8098739495798319"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將上一格跑出的 Logistic Regression 最佳 C 值填入, 觀察測試集的驗證分數\n",
    "lr_clf = LogisticRegression(C = 5.263252631578947)  \n",
    "lr_clf.fit(train_features, train_labels)\n",
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixUCh5TnjTIx"
   },
   "source": [
    "# 對預測目標資料做出最終預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 3374,
     "status": "ok",
     "timestamp": 1621866582084,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "ikIAoUaJjTIy"
   },
   "outputs": [],
   "source": [
    "# 將預測目標資料經過 tokenizer 編碼轉換\n",
    "tokenized_t = df_test['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1621866608755,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "BuXzAJ48jTIy",
    "outputId": "a69babdd-d835-4eec-9b80-0aebead2baaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 73)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以最長字串為準, 將預測目標資料補零成相同長度\n",
    "max_len = 0\n",
    "for i in tokenized_t.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "        \n",
    "padded_t = np.array([i + [0]*(max_len-len(i)) for i in tokenized_t.values])\n",
    "np.array(padded_t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 13269,
     "status": "ok",
     "timestamp": 1621866765316,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "vPf6fUp3yIRA"
   },
   "outputs": [],
   "source": [
    "# 設定 attention_mask, 將計算經過 Bert 生成的 Embedding 結果, 儲存於 last_hidden_states 中\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "attention_mask_t = np.where(padded_t != 0, 1, 0)\n",
    "attention_mask_t = torch.tensor(attention_mask_t).to(torch.int32).to(device)\n",
    "input_ids = torch.tensor(padded_t).to(torch.int32).to(device)\n",
    "\n",
    "model = model.to(device)\n",
    "batch_size = 512\n",
    "turns = input_ids.size(0) // batch_size + 1\n",
    "\n",
    "last_hidden_states = np.zeros((input_ids.size(0), model.config.dim))\n",
    "with torch.no_grad():\n",
    "    for i in range(turns):\n",
    "        begin_idx = i * batch_size\n",
    "        end_idx = begin_idx + batch_size\n",
    "        data = input_ids[begin_idx : end_idx]\n",
    "        mask = attention_mask_t[begin_idx : end_idx]\n",
    "        last_hidden_state = model(data, attention_mask=mask)\n",
    "        \n",
    "        last_hidden_states[begin_idx : end_idx] = last_hidden_state[0][:, 0, :].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1621866784243,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "IcRLNJ-FjTI0",
    "outputId": "40345469-245b-413e-fabb-435b52818ea7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 輸出預測目標資料的預測結果\n",
    "y_pred = lr_clf.predict(last_hidden_states)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1621866843785,
     "user": {
      "displayName": "chi-fen Liao",
      "photoUrl": "",
      "userId": "16137842954465597187"
     },
     "user_tz": -480
    },
    "id": "T64gijV7jTI0"
   },
   "outputs": [],
   "source": [
    "# 生成提交擋\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = df_test['id']\n",
    "submission['target'] = y_pred\n",
    "submission.to_csv('submission_DistilBert.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Day30_作業.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
